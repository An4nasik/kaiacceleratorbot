<h1>Запуск</h1>
<p>Чтобы звапустить бота необходимо запустить файл main.py или docker контейнер под названием an4nasik/kaiacceleratorbot
<br>
Чтобы воспользоватся ботом, пишем @kaiacceleratorbot<br>
Вся инфа о компанрии находится в файле <a href="https://github.com/An4nasik/kaiacceleratorbot/blob/main/company_info.txt">company_info.txt</a></p>
<h2>Товарищ, решившийся протестировать мое чудо творение, см инструкцию ниже</h2>
<p>Заходим <a href="https://ollama.com/download">заходим сюда</a> и нажимаем download</p>
<p>Далее, после запуска того что мы скачали, откроется консоль, не боимся и смело вводим ollama run llama3.2, далее у нас установится сама модель и автоматически запустится</p>
<p>Обратите внимание, что дажеесли закрыть консоль, модель продолжит работать в фоне, поэтому если захотели прекратить общение с нейронкой, либо пишем в консоль /bye, либо жмем ctrl + d. Если закрыли консоль, то находим в диспетчере задачь ollama.exe и выключаем его</p>
<p>После установки можете запускать программу</p>
<p>ВАЖНЫЙ МОМЕНТ!!!</p>
<p>После установки, почему то ollama.exe добавляется в автозапуск(что я очень сильно осуждаю, но поделать ничего не могу). Чтобы ее выключить, заходим в диспетчер задач, переходим во вкладку автозупаска и выключаем ее</p>
<h2>Желающие запустить docker образ</h2>
<p>Собираем docker образ</p>
<p>Запускаем контейнер и прописываем комманды:</p>
<p>  ollama run llama3:8b</p>
<p>  Жмем ctrl+d</p>
<p>  python3 main.py</p>
<p>Вот и все, бот будет работать</p>
